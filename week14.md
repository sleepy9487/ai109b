
## 前言
* 捲積神經網路跟循環神經網路改善了人工智慧這個項目,這類新的技術被統稱為深度學習  
## 人工智慧的方法
* 比對法  
  * 紀錄問題與答案配對後,直接從表格內查出來  
  * ex : 自然語言的處理、eliza聊天系統  
* 推理法  
  * 撰寫規則後,電腦根據規則推論  
  * ex : 邏輯上的推理、專家系統
* 搜尋法  
  * 對所有可能的結果進行系統式的列舉，然後看看有沒有答案
  * ex : AlphaGo,棋類  
* 統計法  
  * 尋找機率最大的解答,可能會結合推理跟搜尋
  * ex : 算圓周率、用亂數驗證中央極限定理
    * 中央極限定理 : 取N個的平均值會趨近於常態分佈
* 優化法  
  * 對每個可能的解答，都給一個分數及權重，找出總分最好的解答  
  * 只要有辦法判斷解答的好壞,就可以使用優化法,無論是影像辨識還是語音辨識,可謂萬物皆優化  
  * ex : 爬山演算法、退火模擬法、梯度下降法  
## 常見神經元的開關函數  
![神經元的開關函數]()  
>用LeakyRelu可以讓平坦的部分可以有點斜率  
## 傳統的神經網路  
 * 多層感知器為主要模型  
 * 使用梯度下降法或者反傳遞演算法  
 * 梯度就是利用微分找出斜率最大的方向並前進(again)  
 * 反傳遞演算法就是利用鏈鎖規則,後一層反推前一層梯度,調整前一層的參數  
 * 梯度下降法仍然在優化  
![多層感知器]()  
## 深度學習的神經網路  
* 除了多層感知器以外,還新增了  
  * 1.卷積神經網路CNN  
  * 2.循環神經網路RNN,LSTM  
  * 3.生成對抗網路GAN  
  * 4.強化學習機制(AlphaGo)  
# 卷積神經網路CNN  
  * 常用於影像辨識
  * 卷積是影像處理的常用手法  
  * 卷積層 : 是一種遮罩函數,檢查有沒有符合遮罩的點,某些遮罩可以取出邊緣、區分深淺
  * 池化層Pool : 取最大值,用途在降低樣本
  * ReLu層
# 循環神經網路RNN
  * 最常被用來處理語言,比如機器翻譯系統
![RNN.LSTM1]
![RNN.LSTM2]
![RNN.LSTM3]
# 生成對抗網路GAN
  * 擅長模仿別人的風格
  * 將素描轉為擬真照片
# 強化學習機制
  * 利用獎勵機制學習
  * 以掃地機器人為例,掃到垃圾就會加一分,作為獎勵
  * Alphago利用強化學習+神經網路+蒙地卡羅搜尋
![卷基層]()
## 資料與圖片來源
  * [人工智慧與神經網路](https://www.slideshare.net/ccckmit/ss-94563680)
>小知識 : 圖靈獎不喜歡頒獎給不確定事務的事項(神經網路)